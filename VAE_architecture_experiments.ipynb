{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"12f209c81f184f3e9a4357472b72e120":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0faa88f1679d4cdd83a77313fb6d4f34","IPY_MODEL_39a58dc5e23e4a579990e0e9ebd6796b","IPY_MODEL_2332a3df09a54bc4907a756188225b68"],"layout":"IPY_MODEL_72b905f8f3b24207ad568decd0b2b0d3"}},"0faa88f1679d4cdd83a77313fb6d4f34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ffa7bedc91a445ab6348927b046de60","placeholder":"​","style":"IPY_MODEL_a496dd3d393b48c789bf03d1b887962c","value":"  0%"}},"39a58dc5e23e4a579990e0e9ebd6796b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae2ee1ebe22a49028852abf808f8b163","max":9,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9c03b7b3d1847c2bc95c863ff7510fa","value":0}},"2332a3df09a54bc4907a756188225b68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51f602fde5d845d781d095caf799aed3","placeholder":"​","style":"IPY_MODEL_b3fa75fc79044a548dc283978ee2f34b","value":" 0/9 [00:00&lt;?, ?it/s]"}},"72b905f8f3b24207ad568decd0b2b0d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffa7bedc91a445ab6348927b046de60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a496dd3d393b48c789bf03d1b887962c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae2ee1ebe22a49028852abf808f8b163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9c03b7b3d1847c2bc95c863ff7510fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"51f602fde5d845d781d095caf799aed3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3fa75fc79044a548dc283978ee2f34b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fede05a52f6f45e596c7f99de6357e57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_faa7523693f04ef99df41d07a4d62f66","IPY_MODEL_fc1f751525b640a5bf7deb1c84ab026d","IPY_MODEL_e6f711664e364d70a6b57ef6cf18cae4"],"layout":"IPY_MODEL_c78bb9adaf4c44d6b077b9d473e7b098"}},"faa7523693f04ef99df41d07a4d62f66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b724a1ac0228457c8e4fae32de7a040d","placeholder":"​","style":"IPY_MODEL_15ae9999b115462da305629e468f4351","value":"  0%"}},"fc1f751525b640a5bf7deb1c84ab026d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_635a789f8d80451f9199439892b9211a","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a3f4f49eba44f3f9887a98e5b717020","value":3}},"e6f711664e364d70a6b57ef6cf18cae4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56b693d499354eed826e167d470033e3","placeholder":"​","style":"IPY_MODEL_96f9c1325bf344e5aab456d46151934c","value":" 3/2000 [00:14&lt;2:02:59,  3.70s/it]"}},"c78bb9adaf4c44d6b077b9d473e7b098":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b724a1ac0228457c8e4fae32de7a040d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ae9999b115462da305629e468f4351":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"635a789f8d80451f9199439892b9211a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a3f4f49eba44f3f9887a98e5b717020":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56b693d499354eed826e167d470033e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96f9c1325bf344e5aab456d46151934c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"810343a83119486183aedbf9f6e0d36e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d819cadfe8c45c2924bb1995c9a20b6","IPY_MODEL_d3ecc1f185de47c5bf95ba589c9c04be","IPY_MODEL_f4474bb766794d32b271bdf5235ae656"],"layout":"IPY_MODEL_e0d6a580155f4ed38b3b69d1d9c1ced6"}},"7d819cadfe8c45c2924bb1995c9a20b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c54fb394b252432783f7322b7b18be7b","placeholder":"​","style":"IPY_MODEL_5a2a1d218e3b449b948facd49c07dcf4","value":"  0%"}},"d3ecc1f185de47c5bf95ba589c9c04be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc936b1b7b7d432fb38802bf50fd1e0b","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f80b811e96d140d2bc6a29cb1cde37fc","value":8}},"f4474bb766794d32b271bdf5235ae656":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_965642d870bd4e51ab8669f25a762f4b","placeholder":"​","style":"IPY_MODEL_1c3f536151334a0fb41e74b60b4b551d","value":" 8/2000 [00:20&lt;1:10:18,  2.12s/it]"}},"e0d6a580155f4ed38b3b69d1d9c1ced6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c54fb394b252432783f7322b7b18be7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a2a1d218e3b449b948facd49c07dcf4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc936b1b7b7d432fb38802bf50fd1e0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f80b811e96d140d2bc6a29cb1cde37fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"965642d870bd4e51ab8669f25a762f4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c3f536151334a0fb41e74b60b4b551d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70f78d00ad44453ea79135f415d52669":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08b1a1687afd47b18f78791810bd1783","IPY_MODEL_6c1a61f0b7ec4952b14042736fc6ea18","IPY_MODEL_db8a191756ac409489f369058bb300e1"],"layout":"IPY_MODEL_6337dabcc1854b2c97f32e65ed7a58f0"}},"08b1a1687afd47b18f78791810bd1783":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8f5f177223a40b59d1073705147170a","placeholder":"​","style":"IPY_MODEL_c1d013e1438746b487894d07c1e7a7ff","value":" 10%"}},"6c1a61f0b7ec4952b14042736fc6ea18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3015b409707c4282bae160ee62e08de3","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a4be6cef5f844308592ee510cdc74c2","value":1}},"db8a191756ac409489f369058bb300e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74836512c9184e8da53f8590e6435e87","placeholder":"​","style":"IPY_MODEL_c03709ec86b54d0f949851395b0f6682","value":" 1/10 [02:17&lt;20:40, 137.86s/it]"}},"6337dabcc1854b2c97f32e65ed7a58f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8f5f177223a40b59d1073705147170a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1d013e1438746b487894d07c1e7a7ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3015b409707c4282bae160ee62e08de3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a4be6cef5f844308592ee510cdc74c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74836512c9184e8da53f8590e6435e87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c03709ec86b54d0f949851395b0f6682":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"id":"POXb9hVNSyT6","execution":{"iopub.status.busy":"2023-12-22T00:07:56.801597Z","iopub.execute_input":"2023-12-22T00:07:56.802474Z","iopub.status.idle":"2023-12-22T00:07:56.832685Z","shell.execute_reply.started":"2023-12-22T00:07:56.802439Z","shell.execute_reply":"2023-12-22T00:07:56.831800Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/dalibra/MMD.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwVTCGlVI6dd","outputId":"ab86f420-db64-4256-fdaf-15caa359c575","execution":{"iopub.status.busy":"2023-12-22T00:07:56.834204Z","iopub.execute_input":"2023-12-22T00:07:56.834465Z","iopub.status.idle":"2023-12-22T00:07:59.378620Z","shell.execute_reply.started":"2023-12-22T00:07:56.834442Z","shell.execute_reply":"2023-12-22T00:07:59.377295Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'MMD'...\nremote: Enumerating objects: 39, done.\u001b[K\nremote: Counting objects: 100% (9/9), done.\u001b[K\nremote: Compressing objects: 100% (9/9), done.\u001b[K\nremote: Total 39 (delta 3), reused 0 (delta 0), pack-reused 30\u001b[K\nReceiving objects: 100% (39/39), 15.40 MiB | 20.69 MiB/s, done.\nResolving deltas: 100% (16/16), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"cd MMD","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJWcdQioJV2C","outputId":"77510cd0-ae2a-4c54-affd-e0af898ac782","execution":{"iopub.status.busy":"2023-12-22T00:07:59.381150Z","iopub.execute_input":"2023-12-22T00:07:59.381568Z","iopub.status.idle":"2023-12-22T00:07:59.404987Z","shell.execute_reply.started":"2023-12-22T00:07:59.381512Z","shell.execute_reply":"2023-12-22T00:07:59.403875Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/working/MMD\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wandb -q","metadata":{"id":"1hqS2bz-UK6D","execution":{"iopub.status.busy":"2023-12-22T00:07:59.406396Z","iopub.execute_input":"2023-12-22T00:07:59.406771Z","iopub.status.idle":"2023-12-22T00:08:11.909110Z","shell.execute_reply.started":"2023-12-22T00:07:59.406736Z","shell.execute_reply":"2023-12-22T00:08:11.907931Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# !pip install theano -q","metadata":{"id":"prbdOy2eLdUK","execution":{"iopub.status.busy":"2023-12-22T00:08:11.911582Z","iopub.execute_input":"2023-12-22T00:08:11.911910Z","iopub.status.idle":"2023-12-22T00:08:11.930434Z","shell.execute_reply.started":"2023-12-22T00:08:11.911881Z","shell.execute_reply":"2023-12-22T00:08:11.929571Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# !sed -i 's/blas_info = np.distutils.__config__.blas_opt_info/blas_info = np.distutils.__config__.blas_ilp64_opt_info/' \"/usr/local/lib/python3.10/dist-packages/theano/configdefaults.py\"\n# !sed -n '1284p' \"/usr/local/lib/python3.10/dist-packages/theano/configdefaults.py\"","metadata":{"id":"yoxPUzwdF7Xm","outputId":"0c4bf3e0-18e7-4f07-f03b-2c99c2c46604","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2023-12-22T00:08:11.931408Z","iopub.execute_input":"2023-12-22T00:08:11.931717Z","iopub.status.idle":"2023-12-22T00:08:11.950178Z","shell.execute_reply.started":"2023-12-22T00:08:11.931692Z","shell.execute_reply":"2023-12-22T00:08:11.949258Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# !python Example_VAE.py -s mnist.npy","metadata":{"id":"ed_fslMj73V-","execution":{"iopub.status.busy":"2023-12-22T00:08:11.951420Z","iopub.execute_input":"2023-12-22T00:08:11.951954Z","iopub.status.idle":"2023-12-22T00:08:11.968628Z","shell.execute_reply.started":"2023-12-22T00:08:11.951921Z","shell.execute_reply":"2023-12-22T00:08:11.967840Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Libraries","metadata":{"id":"RBN8p_W2E-ja"}},{"cell_type":"code","source":"import json\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport wandb\n!wandb login 1b8e8dc9dcf1a34397a04197c4826d3fe7441dae\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"exElj77sErD3","outputId":"48aab55e-2d53-4d4f-90df-9a8063722d95","execution":{"iopub.status.busy":"2023-12-22T00:08:11.969650Z","iopub.execute_input":"2023-12-22T00:08:11.969926Z","iopub.status.idle":"2023-12-22T00:08:18.963552Z","shell.execute_reply.started":"2023-12-22T00:08:11.969902Z","shell.execute_reply":"2023-12-22T00:08:18.962574Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# import VariationalAutoencoder\nimport numpy as np\nimport scipy as sp\nimport time,os\nimport _pickle as cPickle\nimport gzip,copy,pickle\nfrom sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\nfrom mmd import MMD_3_Sample_Test","metadata":{"id":"RYhXoN4ED2ts","execution":{"iopub.status.busy":"2023-12-22T00:08:18.964790Z","iopub.execute_input":"2023-12-22T00:08:18.965179Z","iopub.status.idle":"2023-12-22T00:08:19.651484Z","shell.execute_reply.started":"2023-12-22T00:08:18.965149Z","shell.execute_reply":"2023-12-22T00:08:19.650738Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data loading","metadata":{"id":"j4y89CvfF89M"}},{"cell_type":"code","source":"print(\"Loading MNIST data\")\n#Retrieved from: http://deeplearning.net/data/mnist/mnist.pkl.gz\n\nf = gzip.open('mnist.pkl.gz', 'rb')\n(x_train, t_train), (x_valid, t_valid), (x_test, t_test)  = cPickle.load(f, encoding='latin1')\nf.close()\nx_train=(x_train>0).astype('float')\nx_valid=(x_valid>0).astype('float')\nx_test=(x_test>0).astype('float')\n\nprint(x_train.shape, t_train.shape, x_valid.shape, t_valid.shape, x_test.shape, t_test.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vyTwYVvUDrPN","outputId":"e05bc654-4e23-4f06-d251-f4315148f7e7","execution":{"iopub.status.busy":"2023-12-22T00:08:19.652757Z","iopub.execute_input":"2023-12-22T00:08:19.653399Z","iopub.status.idle":"2023-12-22T00:08:20.791844Z","shell.execute_reply.started":"2023-12-22T00:08:19.653365Z","shell.execute_reply":"2023-12-22T00:08:20.790909Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Loading MNIST data\n(50000, 784) (50000,) (10000, 784) (10000,) (10000, 784) (10000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# VAE","metadata":{}},{"cell_type":"code","source":"class encoder(torch.nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        self.input_dim = args[\"input_dim\"]\n        self.hidden_dim = args[\"hidden_dim\"]\n        self.latent_dim = args[\"latent_dim\"]*2\n\n        self.layers = nn.Sequential(\n            nn.Linear(self.input_dim, self.hidden_dim),\n            nn.Sigmoid(),\n            nn.Linear(self.hidden_dim, self.latent_dim)\n        )\n\n    def forward(self, x: torch.Tensor):\n        return self.layers(x)\n\nclass decoder(torch.nn.Module):\n    def __init__(self, args):\n        super().__init__()\n\n        self.latent_dim = args[\"latent_dim\"]\n        self.hidden_dim = args[\"hidden_dim\"]\n        self.input_dim = args[\"input_dim\"]\n\n        self.layers = nn.Sequential(\n            nn.Linear(self.latent_dim, self.hidden_dim),\n            nn.Sigmoid(),\n            nn.Linear(self.hidden_dim, self.input_dim)\n        )\n\n    def forward(self, x: torch.Tensor):\n        return self.layers(x)\n\n#code from https://github.com/1Konny/Beta-VAE/blob/master\n\ndef reconstruction_loss(x, x_recon, distribution):\n    batch_size = x.size(0)\n    assert batch_size != 0\n\n    if distribution == 'bernoulli':\n        recon_loss = F.binary_cross_entropy_with_logits(x_recon, x, size_average=False).div(batch_size)\n    elif distribution == 'gaussian':\n#         x_recon = F.sigmoid(x_recon)\n        recon_loss = F.mse_loss(x_recon, x, size_average=False).div(batch_size)\n    else:\n        raise ValueError(\"Unknown distribution\")\n\n    return recon_loss\n\n\ndef kl_divergence(mu, logvar):\n    batch_size = mu.size(0)\n    assert batch_size != 0\n    if mu.data.ndimension() == 4:\n        mu = mu.view(mu.size(0), mu.size(1))\n    if logvar.data.ndimension() == 4:\n        logvar = logvar.view(logvar.size(0), logvar.size(1))\n\n    klds = -0.5*(1 + logvar - mu.pow(2) - logvar.exp())\n    total_kld = klds.sum(1).mean(0, True)\n    dimension_wise_kld = klds.mean(0)\n    mean_kld = klds.mean(1).mean(0, True)\n\n    return total_kld, dimension_wise_kld, mean_kld\n\n\ndef reparametrize(mu, logvar):\n    std = logvar.div(2).exp()\n    eps = Variable(std.data.new(std.size()).normal_())\n    return mu + std*eps\n\n\nclass View(nn.Module):\n    def __init__(self, size):\n        super(View, self).__init__()\n        self.size = size\n\n    def forward(self, tensor):\n        return tensor.view(self.size)\n\n\nclass BetaVAE_H(nn.Module):\n    \"\"\"Model proposed in original beta-VAE paper(Higgins et al, ICLR, 2017).\"\"\"\n\n    def __init__(self, encoder, decoder, **args):\n        super(BetaVAE_H, self).__init__()\n        \n        self.input_dim = args[\"input_dim\"]\n        self.z_dim = args[\"latent_dim\"]\n        self.beta = args[\"beta\"]\n        self.decoder_dist = args[\"data_prior\"] #\"gaussian\"/\"bernoulli\"\n        self.device = args[\"device\"]\n        \n        self.encoder = encoder\n        self.decoder = decoder\n\n        self.prior_mu = torch.zeros(self.z_dim).to(device)\n        self.log_prior_sigma = torch.zeros(self.z_dim).to(device)\n        self.rng = np.random.default_rng()\n\n    def forward(self, x):\n        x_recon, mu, logvar = self._reconstruct(x)\n        \n        recon_loss = reconstruction_loss(x, x_recon, self.decoder_dist)\n        total_kld, dim_wise_kld, mean_kld = kl_divergence(mu, logvar)\n        \n        beta_vae_loss = recon_loss + self.beta*total_kld\n\n        return {\n            'loss': beta_vae_loss,\n            '-log p(x|z)': recon_loss,\n            'kl': total_kld,\n            'decoded_imgs': x_recon\n        }\n\n    def _encode(self, x):\n        return self.encoder(x)\n    \n    def encode(self, x):\n        distributions = self._encode(x)\n        return distributions[:, :self.z_dim]\n\n    def _decode(self, z):\n        return self.decoder(z)\n    \n    def _reconstruct(self, x):\n        distributions = self._encode(x)\n        mu = distributions[:, :self.z_dim]\n        logvar = distributions[:, self.z_dim:]\n        z = reparametrize(mu, logvar)\n        x_recon = self._decode(z)\n        return x_recon, mu, logvar\n    \n    def reconstruct(self, x):\n        x_recon, mu, logvar = self._reconstruct(x)\n        return x_recon\n    \n    def sample_from_p_z(self, num_samples):\n        return self.prior_mu + torch.exp(self.log_prior_sigma)*torch.tensor(\n            self.rng.multivariate_normal(mean=np.ones(self.z_dim), cov=np.eye(self.z_dim), size=num_samples), \n            requires_grad=False\n        ).to(torch.float32).to(self.device)\n    \n    def sample(self, num_samples):\n        return self._decode(self.sample_from_p_z(num_samples))\n    \nclass Trainer():\n    def __init__(self, model, lr, bs, device):\n        self.lr = lr\n        self.bs = bs\n        self.device = device\n        self.model = self.to_device(model)\n        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr)\n        \n    def to_cpu(self, x):\n        return x.to(\"cpu\")\n        \n    def to_device(self, x):\n        return x.to(self.device)\n        \n    def create_dataloader(self, data):\n        return DataLoader(data, shuffle=True, batch_size = self.bs, num_workers=0)\n        \n    def iterate(self, data):\n        self.model.train()\n        dataloader = self.create_dataloader(data)\n        for batch in dataloader:\n            batch = self.to_device(batch).to(torch.float32)\n            loss = self.model(batch)[\"loss\"]\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            \n    def getLowerBound(self, data):\n        self.model.eval()\n        dataloader = self.create_dataloader(data)\n        running_loss = 0\n        for batch in dataloader:\n            batch = self.to_device(batch).to(torch.float32)\n            loss = self.model(batch)[\"loss\"]\n            running_loss += loss\n        return -running_loss/len(dataloader)\n    \n    def sample(self, N):\n        return self.to_cpu(self.model.sample(N)).detach().numpy()\n    \n    def encode(self, x):\n        return self.model.encode(self.to_device(torch.tensor(x).to(torch.float32))).detach().cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:08:20.794451Z","iopub.execute_input":"2023-12-22T00:08:20.794788Z","iopub.status.idle":"2023-12-22T00:08:20.864840Z","shell.execute_reply.started":"2023-12-22T00:08:20.794761Z","shell.execute_reply":"2023-12-22T00:08:20.864039Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Train config","metadata":{"id":"g51Vd-ZKFV4i"}},{"cell_type":"code","source":"data_train=x_train\nsamp_size=5000\n# samp_size=1000\nverbose=True\nruns=10\n# runs=1\n# ratios=np.array([0.9, 4.0, 0.5, 2.0, 0.8, 3.0, 1.5, 1.9, 2.5])\n# ratios=np.array([1.0])\n# t_size2=1500\nt_size = 25000\n# t_size = 1000\n\ndimZ = 20\nHU_decoder = 400\nHU_encoder = HU_decoder\n# dimZ2 = 20\n# HU_decoder2 = 400\n# HU_encoder2 = HU_decoder2\ndimZ2_HU_decoder2_list = [(50, 400)]\n# dimZ2_HU_decoder2_list = [(5, 200)]\n\nbatch_size = 100\nL = 1\nlearning_rate = 0.01\nsig=0.05\n# maxiter=10\nmaxiter=2000","metadata":{"id":"FMi39cYKEke6","execution":{"iopub.status.busy":"2023-12-22T01:44:13.977639Z","iopub.execute_input":"2023-12-22T01:44:13.978573Z","iopub.status.idle":"2023-12-22T01:44:14.030591Z","shell.execute_reply.started":"2023-12-22T01:44:13.978538Z","shell.execute_reply":"2023-12-22T01:44:14.029734Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"for dimZ2, HU_decoder2 in tqdm(dimZ2_HU_decoder2_list):\n    HU_encoder2=HU_decoder2\n#     t_size1=int(t_size2/ratio)\n#     print(f\"{t_size1 = }, {t_size2 = }\")\n\n    config={\n        \"samp_size\": samp_size,\n        \"runs\": runs,\n#         \"ratio\": ratio,\n#         \"t_size2\": t_size2,\n#         \"t_size1\": t_size1,\n        \"t_size\": t_size,\n        \"dimZ\": dimZ,\n        \"HU_decoder\": HU_decoder,\n        \"HU_encoder\": HU_encoder,\n        \"dimZ2\": dimZ2,\n        \"HU_decoder2\": HU_decoder2,\n        \"HU_encoder2\": HU_encoder2,\n        \"batch_size\": batch_size,\n        \"L\": L,\n        \"learning_rate\": learning_rate,\n        \"sig\": sig,\n        \"maxiter\": maxiter\n    }\n    print(config)\n\n    results = {\n        \"pvalue_win1\" : [],\n        \"tstat_win1\": [],\n        \"sigma_win1\": [],\n        \"pvalue_win2\" : [],\n        \"tstat_win2\": [],\n        \"sigma_win2\": [],\n        \"n_wins_1\": 0,\n        \"n_wins_2\": 0,\n        \"n_draws\": 0\n    }\n\n    #dataset\n#     set1,set2 = train_test_split(range(data.shape[0]), train_size=t_size1+t_size2)\n    set1,set2 = train_test_split(range(data_train.shape[0]), train_size=t_size)\n#     data1 = data[set1[0:t_size1],:]\n#     data2 = data[set1[t_size1:t_size2+t_size1],:]\n    data = data_train[set1[0:t_size],:]\n    set2=set2[0:samp_size]\n    data_holdout=data_train[set2,:]\n#     print(f\"{len(data1) = }, {len(data2) = }, {len(data_holdout) = }\")\n    print(f\"{len(data) = }, {len(data_holdout) = }\")\n#     [N1,dimX] = data1.shape\n#     [N2,dimX] = data2.shape\n    [N,dimX] = data.shape\n\n    #model initialization    \n#     encoder1 = VariationalAutoencoder.VA(HU_decoder, HU_encoder, dimX, dimZ, batch_size, L, learning_rate, continous=False)\n#     encoder2 = VariationalAutoencoder.VA(HU_decoder2, HU_encoder2, dimX, dimZ2, batch_size, L, learning_rate, continous=False)\n#     encoder1.createGradientFunctions()\n#     encoder2.createGradientFunctions()\n#     encoder1.initParams()\n#     encoder2.initParams()\n    model_config = {\n        \"input_dim\" : dimX,\n        \"hidden_dim\": HU_decoder,\n        \"latent_dim\": dimZ,\n        \"data_prior\": \"bernoulli\",\n        \"beta\": 1,\n        \"device\": device\n    }\n    model_config2 = {\n        \"input_dim\" : dimX,\n        \"hidden_dim\": HU_decoder2,\n        \"latent_dim\": dimZ2,\n        \"data_prior\": \"bernoulli\",\n        \"beta\": 1,\n        \"device\": device\n    }\n    model1 = BetaVAE_H(encoder(model_config), decoder(model_config), **model_config)\n    model2 = BetaVAE_H(encoder(model_config2), decoder(model_config2), **model_config2)\n    encoder1 = Trainer(model1, learning_rate, batch_size, device)\n    encoder2 = Trainer(model2, learning_rate, batch_size, device)\n\n    begin = time.time()\n    testlowerbound1=testlowerbound2=-np.Inf\n\n    #training\n    run = wandb.init(name=f\"hu2={HU_decoder2}, dimz2={dimZ2}\", project=\"Maximum mean discrepancy test\", config=config)\n\n    wandb.define_metric(\"vae1_step\")\n    wandb.define_metric(\"lb_train_1\", step_metric=\"vae1_step\")\n    wandb.define_metric(\"lb_test_1\", step_metric=\"vae1_step\")\n\n    for j in tqdm(range(maxiter)):\n#         encoder1.iterate(data1)\n        encoder1.iterate(data)\n        if j%1 == 0:\n            oldlower=testlowerbound1\n#             train_lower1=encoder1.getLowerBound(data1).detach()\n            train_lower1=encoder1.getLowerBound(data).detach()\n            testlowerbound1 = encoder1.getLowerBound(data_holdout).detach()\n#             lbtrain = train_lower1/float(N1)\n#             lbtest = testlowerbound1/samp_size\n            lbtrain = train_lower1\n            lbtest = testlowerbound1\n\n            if(verbose):\n                print(f\"Encoder 1 Iteration {j}| lower bound train = {lbtrain} |lower bound test 1 = {lbtest}\")\n            wandb.log({\"vae1_step\": j, \"lb_train_1\": lbtrain, \"lb_test_1\": lbtest})\n\n            if(oldlower>=testlowerbound1): break\n            best_encoder1=copy.deepcopy(encoder1)\n\n    encoder1=best_encoder1\n\n    wandb.define_metric(\"vae2_step\")\n    wandb.define_metric(\"lb_train_2\", step_metric=\"vae2_step\")\n    wandb.define_metric(\"lb_test_2\", step_metric=\"vae2_step\")\n\n    for j in tqdm(range(maxiter)):\n#         encoder2.iterate(data2)\n        encoder2.iterate(data)\n\n        if j%1 == 0:\n            oldlower=testlowerbound2\n#             train_lower2=encoder2.getLowerBound(data2).detach()\n            train_lower2=encoder2.getLowerBound(data).detach()\n            testlowerbound2 = encoder2.getLowerBound(data_holdout).detach()\n#             lbtrain = train_lower2/float(N2)\n#             lbtest = testlowerbound2/samp_size\n            lbtrain = train_lower2\n            lbtest = testlowerbound2\n\n            if(verbose):\n                print(\"Encoder 2 Iteration %d| lower bound train = %.2f |lower bound test 1= %.2f\"\n                    % (j, lbtrain, lbtest))\n            wandb.log({\"vae2_step\": j, \"lb_train_2\": lbtrain, \"lb_test_2\": lbtest})\n\n            if(oldlower>testlowerbound2):\n                break\n            best_encoder2=copy.deepcopy(encoder2)\n\n    encoder2=best_encoder2\n\n    end=time.time()\n\n    #test\n    for _ in tqdm(range(runs)):\n        samples1=encoder1.sample(N=samp_size)\n        samples2=encoder2.sample(N=samp_size)\n\n        pvalue_win1, tstat_win1, sigma_win1, MMDXY_win1, MMDXZ_win1 = MMD_3_Sample_Test(data_holdout, samples1, samples2, computeMMDs=False)\n        print(\"win1: pvalue: %.2f\"%(pvalue_win1))\n        results[\"pvalue_win1\"].append(pvalue_win1)\n        results[\"tstat_win1\"].append(tstat_win1)\n        results[\"sigma_win1\"].append(sigma_win1)\n        pvalue_win2, tstat_win2, sigma_win2, MMDXY_win2, MMDXZ_win2 = MMD_3_Sample_Test(data_holdout, samples2, samples1, computeMMDs=False)\n        print(\"win2: pvalue: %.2f\"%(pvalue_win2))\n        results[\"pvalue_win2\"].append(pvalue_win2)\n        results[\"tstat_win2\"].append(tstat_win2)\n        results[\"sigma_win2\"].append(sigma_win2)\n\n        alpha = 0.05\n        if pvalue_win1 <= alpha and pvalue_win2 > alpha:\n            results[\"n_wins_2\"] += 1\n        elif pvalue_win1 > alpha and pvalue_win2 <= alpha:\n            results[\"n_wins_1\"] += 1\n        else:\n            results[\"n_draws\"] += 1\n    print(\"n_wins_1:\", results[\"n_wins_1\"], \", n_wins_2:\", results[\"n_wins_2\"], \", n_draws:\", results[\"n_draws\"])\n\n    data1_enc=encoder1.encode(x_valid)\n    data2_enc=encoder2.encode(x_valid)\n    test1_enc=encoder1.encode(x_test)\n    test2_enc=encoder2.encode(x_test)\n\n    LogReg_VAE = linear_model.LogisticRegression(max_iter=1000)\n    LogReg_VAE.fit(data1_enc,t_valid)\n    vae1_score = LogReg_VAE.score(test1_enc, t_test)\n    LogReg_VAE = linear_model.LogisticRegression(max_iter=1000)\n    LogReg_VAE.fit(data2_enc,t_valid)\n    vae2_score = LogReg_VAE.score(test2_enc, t_test)\n    print(\"Accuracy 1:%.2f Accuracy2:%.2f\"%(vae1_score,vae2_score))\n\n#     wandb.define_metric(\"ratio\")\n#     wandb.define_metric(\"n_wins_1\", step_metric=\"ratio\")\n#     wandb.define_metric(\"n_wins_2\", step_metric=\"ratio\")\n#     wandb.define_metric(\"n_draws\", step_metric=\"ratio\")\n#     wandb.define_metric(\"accuracy_1\", step_metric=\"ratio\")\n#     wandb.define_metric(\"accuracy_2\", step_metric=\"ratio\")\n    wandb.log({\n#         \"ratio\": ratio,\n        \"n_wins_1\": results[\"n_wins_1\"],\n        \"n_wins_2\": results[\"n_wins_2\"],\n        \"n_draws\": results[\"n_draws\"],\n        \"accuracy_1\": vae1_score,\n        \"accuracy_2\": vae2_score\n    })\n\n    wandb.finish()\n\n    with open(f\"log_hu2={HU_decoder2}_dimz2={dimZ2}.json\", \"w\") as f:\n        json.dump(results, f, indent=4)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":599,"referenced_widgets":["12f209c81f184f3e9a4357472b72e120","0faa88f1679d4cdd83a77313fb6d4f34","39a58dc5e23e4a579990e0e9ebd6796b","2332a3df09a54bc4907a756188225b68","72b905f8f3b24207ad568decd0b2b0d3","3ffa7bedc91a445ab6348927b046de60","a496dd3d393b48c789bf03d1b887962c","ae2ee1ebe22a49028852abf808f8b163","b9c03b7b3d1847c2bc95c863ff7510fa","51f602fde5d845d781d095caf799aed3","b3fa75fc79044a548dc283978ee2f34b","fede05a52f6f45e596c7f99de6357e57","faa7523693f04ef99df41d07a4d62f66","fc1f751525b640a5bf7deb1c84ab026d","e6f711664e364d70a6b57ef6cf18cae4","c78bb9adaf4c44d6b077b9d473e7b098","b724a1ac0228457c8e4fae32de7a040d","15ae9999b115462da305629e468f4351","635a789f8d80451f9199439892b9211a","1a3f4f49eba44f3f9887a98e5b717020","56b693d499354eed826e167d470033e3","96f9c1325bf344e5aab456d46151934c","810343a83119486183aedbf9f6e0d36e","7d819cadfe8c45c2924bb1995c9a20b6","d3ecc1f185de47c5bf95ba589c9c04be","f4474bb766794d32b271bdf5235ae656","e0d6a580155f4ed38b3b69d1d9c1ced6","c54fb394b252432783f7322b7b18be7b","5a2a1d218e3b449b948facd49c07dcf4","bc936b1b7b7d432fb38802bf50fd1e0b","f80b811e96d140d2bc6a29cb1cde37fc","965642d870bd4e51ab8669f25a762f4b","1c3f536151334a0fb41e74b60b4b551d","70f78d00ad44453ea79135f415d52669","08b1a1687afd47b18f78791810bd1783","6c1a61f0b7ec4952b14042736fc6ea18","db8a191756ac409489f369058bb300e1","6337dabcc1854b2c97f32e65ed7a58f0","f8f5f177223a40b59d1073705147170a","c1d013e1438746b487894d07c1e7a7ff","3015b409707c4282bae160ee62e08de3","4a4be6cef5f844308592ee510cdc74c2","74836512c9184e8da53f8590e6435e87","c03709ec86b54d0f949851395b0f6682"]},"id":"BGZfVXNf2rSq","outputId":"d9694073-fb09-4384-b1c9-ce04a2c5a58c","execution":{"iopub.status.busy":"2023-12-22T01:44:14.150841Z","iopub.execute_input":"2023-12-22T01:44:14.151149Z","iopub.status.idle":"2023-12-22T01:51:45.313451Z","shell.execute_reply.started":"2023-12-22T01:44:14.151125Z","shell.execute_reply":"2023-12-22T01:51:45.312563Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bd450f3b21545fd84d287630a5022a4"}},"metadata":{}},{"name":"stdout","text":"{'samp_size': 5000, 'runs': 10, 't_size': 25000, 'dimZ': 20, 'HU_decoder': 400, 'HU_encoder': 400, 'dimZ2': 50, 'HU_decoder2': 400, 'HU_encoder2': 400, 'batch_size': 100, 'L': 1, 'learning_rate': 0.01, 'sig': 0.05, 'maxiter': 2000}\nlen(data) = 25000, len(data_holdout) = 5000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/MMD/wandb/run-20231222_014414-8lzm84ol</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/dmitriykornilov_team/Maximum%20mean%20discrepancy%20test/runs/8lzm84ol' target=\"_blank\">hu2=400, dimz2=50</a></strong> to <a href='https://wandb.ai/dmitriykornilov_team/Maximum%20mean%20discrepancy%20test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/dmitriykornilov_team/Maximum%20mean%20discrepancy%20test' target=\"_blank\">https://wandb.ai/dmitriykornilov_team/Maximum%20mean%20discrepancy%20test</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/dmitriykornilov_team/Maximum%20mean%20discrepancy%20test/runs/8lzm84ol' target=\"_blank\">https://wandb.ai/dmitriykornilov_team/Maximum%20mean%20discrepancy%20test/runs/8lzm84ol</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f8650a7a47c46678d137fbd9358a1dd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n  warnings.warn(warning.format(ret))\n","output_type":"stream"},{"name":"stdout","text":"Encoder 1 Iteration 0| lower bound train = tensor([-160.0698], device='cuda:0') |lower bound test 1 = tensor([-159.8709], device='cuda:0')\nEncoder 1 Iteration 1| lower bound train = tensor([-127.0230], device='cuda:0') |lower bound test 1 = tensor([-127.8976], device='cuda:0')\nEncoder 1 Iteration 2| lower bound train = tensor([-113.1850], device='cuda:0') |lower bound test 1 = tensor([-114.2562], device='cuda:0')\nEncoder 1 Iteration 3| lower bound train = tensor([-107.4794], device='cuda:0') |lower bound test 1 = tensor([-108.8017], device='cuda:0')\nEncoder 1 Iteration 4| lower bound train = tensor([-102.7829], device='cuda:0') |lower bound test 1 = tensor([-104.6312], device='cuda:0')\nEncoder 1 Iteration 5| lower bound train = tensor([-100.8791], device='cuda:0') |lower bound test 1 = tensor([-103.0114], device='cuda:0')\nEncoder 1 Iteration 6| lower bound train = tensor([-99.5503], device='cuda:0') |lower bound test 1 = tensor([-102.1449], device='cuda:0')\nEncoder 1 Iteration 7| lower bound train = tensor([-97.8210], device='cuda:0') |lower bound test 1 = tensor([-100.5931], device='cuda:0')\nEncoder 1 Iteration 8| lower bound train = tensor([-95.6743], device='cuda:0') |lower bound test 1 = tensor([-98.8499], device='cuda:0')\nEncoder 1 Iteration 9| lower bound train = tensor([-94.4696], device='cuda:0') |lower bound test 1 = tensor([-97.9015], device='cuda:0')\nEncoder 1 Iteration 10| lower bound train = tensor([-94.7766], device='cuda:0') |lower bound test 1 = tensor([-98.0991], device='cuda:0')\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa022cba2a4b4e348e032a43b626e5a5"}},"metadata":{}},{"name":"stdout","text":"Encoder 2 Iteration 0| lower bound train = -179.49 |lower bound test 1= -178.78\nEncoder 2 Iteration 1| lower bound train = -134.28 |lower bound test 1= -134.65\nEncoder 2 Iteration 2| lower bound train = -118.54 |lower bound test 1= -119.45\nEncoder 2 Iteration 3| lower bound train = -109.98 |lower bound test 1= -111.62\nEncoder 2 Iteration 4| lower bound train = -104.97 |lower bound test 1= -106.76\nEncoder 2 Iteration 5| lower bound train = -102.65 |lower bound test 1= -104.79\nEncoder 2 Iteration 6| lower bound train = -100.38 |lower bound test 1= -102.77\nEncoder 2 Iteration 7| lower bound train = -98.90 |lower bound test 1= -101.71\nEncoder 2 Iteration 8| lower bound train = -97.54 |lower bound test 1= -100.31\nEncoder 2 Iteration 9| lower bound train = -96.68 |lower bound test 1= -99.82\nEncoder 2 Iteration 10| lower bound train = -95.71 |lower bound test 1= -98.84\nEncoder 2 Iteration 11| lower bound train = -95.28 |lower bound test 1= -98.80\nEncoder 2 Iteration 12| lower bound train = -93.72 |lower bound test 1= -97.44\nEncoder 2 Iteration 13| lower bound train = -93.47 |lower bound test 1= -96.98\nEncoder 2 Iteration 14| lower bound train = -93.09 |lower bound test 1= -96.77\nEncoder 2 Iteration 15| lower bound train = -92.60 |lower bound test 1= -96.28\nEncoder 2 Iteration 16| lower bound train = -91.81 |lower bound test 1= -95.74\nEncoder 2 Iteration 17| lower bound train = -92.16 |lower bound test 1= -96.27\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75a103f5fa51483898bcecc0f20823f8"}},"metadata":{}},{"name":"stdout","text":"win1: pvalue: 1.00\nwin2: pvalue: 0.00\nwin1: pvalue: 1.00\nwin2: pvalue: 0.00\nwin1: pvalue: 1.00\nwin2: pvalue: 0.00\nwin1: pvalue: 1.00\nwin2: pvalue: 0.00\nwin1: pvalue: 1.00\nwin2: pvalue: 0.00\nwin1: pvalue: 1.00\nwin2: pvalue: 0.00\nwin1: pvalue: 1.00\nwin2: pvalue: 0.00\nwin1: pvalue: 1.00\nwin2: pvalue: 0.00\nwin1: pvalue: 1.00\nwin2: pvalue: 0.00\nwin1: pvalue: 1.00\nwin2: pvalue: 0.00\nn_wins_1: 10 , n_wins_2: 0 , n_draws: 0\nAccuracy 1:0.89 Accuracy2:0.90\n","output_type":"stream"},{"name":"stderr","text":"wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_1</td><td>▁</td></tr><tr><td>accuracy_2</td><td>▁</td></tr><tr><td>lb_test_1</td><td>▁▅▆▇▇▇█████</td></tr><tr><td>lb_test_2</td><td>▁▅▆▇▇▇▇▇██████████</td></tr><tr><td>lb_train_1</td><td>▁▅▆▇▇▇▇████</td></tr><tr><td>lb_train_2</td><td>▁▅▆▇▇▇▇▇██████████</td></tr><tr><td>n_draws</td><td>▁</td></tr><tr><td>n_wins_1</td><td>▁</td></tr><tr><td>n_wins_2</td><td>▁</td></tr><tr><td>vae1_step</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>vae2_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_1</td><td>0.8877</td></tr><tr><td>accuracy_2</td><td>0.9007</td></tr><tr><td>lb_test_1</td><td>-98.09911</td></tr><tr><td>lb_test_2</td><td>-96.27264</td></tr><tr><td>lb_train_1</td><td>-94.77662</td></tr><tr><td>lb_train_2</td><td>-92.15939</td></tr><tr><td>n_draws</td><td>0</td></tr><tr><td>n_wins_1</td><td>10</td></tr><tr><td>n_wins_2</td><td>0</td></tr><tr><td>vae1_step</td><td>10</td></tr><tr><td>vae2_step</td><td>17</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">hu2=400, dimz2=50</strong> at: <a href='https://wandb.ai/dmitriykornilov_team/Maximum%20mean%20discrepancy%20test/runs/8lzm84ol' target=\"_blank\">https://wandb.ai/dmitriykornilov_team/Maximum%20mean%20discrepancy%20test/runs/8lzm84ol</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20231222_014414-8lzm84ol/logs</code>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Link to WandB\nhttps://wandb.ai/dmitriykornilov_team/Maximum%20mean%20discrepancy%20test/workspace?workspace=user-dmitriykornilov","metadata":{}},{"cell_type":"code","source":"","metadata":{"id":"tYgscDwK4Yo6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}